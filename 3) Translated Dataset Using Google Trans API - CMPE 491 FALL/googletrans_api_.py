# -*- coding: utf-8 -*-
"""GoogleTrans_API .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r-18Xx1y48uO8Dv-IcycvSyMCDWn5Si7
"""

!pip3 install googletrans==3.1.0a0

import numpy as np
import pandas as pd
import sklearn as sk
import glob
import os
import googletrans
from googletrans import Translator

"""# Preprocess fake and true dataset"""

data_path = 'Fake.csv'
fake = pd.read_csv(data_path, error_bad_lines=False)

data_path = 'True.csv'
real = pd.read_csv(data_path, error_bad_lines=False)

real.head()

fake.head()

#First Creating list of index that do not have publication part
unknown_publishers = []
for index,row in enumerate(real.text.values):
    try:
        record = row.split(" -", maxsplit=1)
        #if no text part is present, following will give error
        record[1]
        #if len of piblication part is greater than 260
        #following will give error, ensuring no text having "-" in between is counted
        assert(len(record[0]) < 260)
    except:
        unknown_publishers.append(index)

real.iloc[unknown_publishers].text  #the result shows that 8970th line is empty

real.iloc[8970]
#chechking that is empty

#Seperating Publication info, from actual text
publisher = []
tmp_text = []
for index,row in enumerate(real.text.values):
    if index in unknown_publishers:
        #Add unknown of publisher not mentioned
        tmp_text.append(row)
        
        publisher.append("Unknown")
        continue
    record = row.split(" -", maxsplit=1)
    publisher.append(record[0])
    tmp_text.append(record[1])

#Replace existing text column with new text
#add seperate column for publication info
real["publisher"] = publisher
real["text"] = tmp_text

del publisher, tmp_text, record, unknown_publishers

real.head()

#checking for rows with empty text like row:8970
[index for index,text in enumerate(real.text.values) if str(text).strip() == '']
#seems only one :)

#dropping this record
real = real.drop(8970, axis=0)

# checking for the same in fake news

empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']
print(f"No of empty rows: {len(empty_fake_index)}")
fake.iloc[empty_fake_index].tail()

#Getting Total Rows
print(f"Total Records:\t{real.shape[0]}")

#Counting by Subjects 
for key,count in real.subject.value_counts().iteritems():
  print(f"{key}:\t{count}")

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x="subject", data=real)
plt.show()

!pip install wordcloud

#WordCloud For Real News
import wordcloud
import nltk
from wordcloud import WordCloud
nltk.download('stopwords')
text = ''
for news in real.text.values:
    text += f" {news}"
wordcloud = WordCloud(
    width = 300,
    height = 200,
    background_color = 'black',
    stopwords = set(nltk.corpus.stopwords.words("english"))).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()
del text

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import re
from wordcloud import WordCloud

# Adding class Information
real["class"] = 1
fake["class"] = 0

real.isnull().sum()

fake.isnull().sum()

#Combining Title and Text
real["text"] = real["title"] + " " + real["text"]
fake["text"] = fake["title"] + " " + fake["text"]

# Subject is diffrent for real and fake thus dropping it
# Aldo dropping Date, title and Publication Info of real
real = real.drop(["subject", "date","title",  "publisher"], axis=1)
fake = fake.drop(["subject", "date", "title"], axis=1)

#Combining both into new dataframe
data = real.append(fake, ignore_index=True)
del real, fake

data.head()

data.isnull().sum()

data.to_csv("fake_real_combined.csv", encoding='utf-8-sig')

"""# TRANSLATE PART"""

translator = Translator()

data.isnull().sum()

data.head()

data['text'] = data['text'].apply(translator.translate, src='en', dest='tr').apply(getattr, args=('text',))

data.head()

data.to_csv("fake_real_tr.csv", encoding='utf-8-sig')

data.shape

data.tail()

import wordcloud
from wordcloud import WordCloud
import nltk
from wordcloud import WordCloud
from wordcloud import ImageColorGenerator
from wordcloud import STOPWORDS
import matplotlib.pyplot as plt

# Start with one review:
text = data.text[5]

# Create and generate a word cloud image:
wordcloud = WordCloud().generate(text)

# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()