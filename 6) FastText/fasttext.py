# -*- coding: utf-8 -*-
"""FastTEXT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5Ht6ZX9nzoDEJ_sNartyroOOx5LOqwX
"""

!pip install fasttext

# Import required libraries
import fasttext.util
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# Load the dataset
data_path = 'clean_news.csv'
df = pd.read_csv(data_path, error_bad_lines=False)

# Display the first 10 rows of the DataFrame
df.head(10)

import resource
#Set the maximum size of the data segment that can be allocated by a process to 10 GB
resource.setrlimit(resource.RLIMIT_DATA, (10 * 1024**3, -1))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import fasttext
from sklearn.metrics import confusion_matrix
#Split the dataset into train and test sets
train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)

# Save the train and test sets as text files in fastText format
train_df['fasttext_data'] = '__label__' + train_df['Label'] + ' ' + train_df['Body']
train_df[['fasttext_data']].to_csv('train.txt', index=False, header=False)
test_df['fasttext_data'] = '__label__' + test_df['Label'] + ' ' + test_df['Body']
test_df[['fasttext_data']].to_csv('test.txt', index=False, header=False)

#Train the FastText model
model = fasttext.train_supervised('train.txt', epoch=5, lr=0.1, wordNgrams=2, bucket=1000, dim=10, loss='hs')

#Test the FastText model
y_pred = model.predict([text for text in test_df['Body'].values])
y_pred_labels = [label[0].split('__')[-1] for label in y_pred[0]]
y_true_labels = test_df['Label'].tolist()
accuracy = accuracy_score(y_true_labels, y_pred_labels)

#Print the evaluation metrics
print("Accuracy:", accuracy_score(y_true_labels, y_pred_labels))
print("Precision:", precision_score(y_true_labels, y_pred_labels, average='macro'))
print("Recall:", recall_score(y_true_labels, y_pred_labels, average='macro'))
print("F1 Score:", f1_score(y_true_labels, y_pred_labels, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_true_labels, y_pred_labels))

#Display the contents of the train_df variable
print(train_df)

#Display the contents of the test_df variable
print(test_df)

#Get the number of items in the train_df object
len(train_df)

# Get the number of items in the test_df object
len(test_df)

"""LOGISTIC REGRESSION"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_vec, y_train)

# Make predictions on the test data
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_true_labels, y_pred_labels))
print("Precision:", precision_score(y_true_labels, y_pred_labels, average='macro'))
print("Recall:", recall_score(y_true_labels, y_pred_labels, average='macro'))
print("F1 Score:", f1_score(y_true_labels, y_pred_labels, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_true_labels, y_pred_labels))

"""DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a decision tree classifier
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a random forest classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""GRADIENT BOOSTING"""

from sklearn.ensemble import GradientBoostingClassifier

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a gradient boosting classifier
model = GradientBoostingClassifier(random_state=42)
model.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""SUPPORT VECTOR MACHINE"""

from sklearn.svm import SVC

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a support vector machine classifier
model = SVC(kernel='linear', random_state=42)
model.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

#Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

#Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

#Train a KNN classifier
model = KNeighborsClassifier()
model.fit(X_train_vec, y_train)

#Make predictions on the test set
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""NAIVE BAYES"""

from sklearn.naive_bayes import MultinomialNB

#Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df['Body'], df['Label'], test_size=0.3, random_state=42)

#Vectorize the text data
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

#Train a naive bayes classifier
model = MultinomialNB()
model.fit(X_train_vec, y_train)

#Make predictions on the test set.
y_pred = model.predict(X_test_vec)

# Print the evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro')) 
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))