# -*- coding: utf-8 -*-
"""Data_Preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15a7Y6wH4-aBCLYEVWyYftNWorOmKANft
"""

import pandas as pd
import numpy as np
import re
from bs4 import BeautifulSoup
import nltk
import string
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')

data_path = 'news.csv'
df = pd.read_csv(data_path, error_bad_lines=False)

df.head()

df.shape

"""Checking the total number of the elements before preprocess steps"""

# Total count of HTML elements
html_element_count = df['Body'].str.count('<[^>]+>').sum()
print("HTML Element Count:", html_element_count)

# Total number of special characters
special_char_count = df['Body'].apply(lambda text: sum(1 for char in text if char in string.punctuation)).sum()
print("Special Character Count:", special_char_count)

# Total number of newlines and white spaces
whitespace_count = df['Body'].str.count('\s').sum()
print("Whitespace Count:", whitespace_count)

# Total number of capital letters
uppercase_count = df['Body'].str.count(r'[A-Z]').sum()
print("Uppercase Count:", uppercase_count)

# Total number of stop-words
stopwords_list = stopwords.words('turkish')  # Turkish stop-words list
stopwords_count = df['Body'].apply(lambda text: len([word for word in text.split() if word.lower() in stopwords_list])).sum()
print("Stopwords Count:", stopwords_count)

"""### Data Preprocessing Steps

* Remove HTML elements

* Filter special characters

* Eliminate newlines and white spaces

* Encode in lowercase letters

* Remove stop words
"""

def preprocess_text(text):
    # Remove HTML elements
    text = BeautifulSoup(text, "html.parser").get_text()
    
    # Filter special characters
    text = re.sub(r"[^a-zA-ZğüşıöçĞÜŞİÖÇ\s]", "", text)
    
    # Eliminate newlines and white spaces
    text = re.sub(r"\s+", " ", text)
    
    # Encode in lowercase letters
    text = text.lower()
    
    # Remove stop words and extra whitespaces
    stop_words = set(stopwords.words('turkish'))
    words = text.split()
    words = [word for word in words if word.lower() not in stop_words]
    text = ' '.join(words)
  
    return text

df['Body'] = df['Body'].apply(preprocess_text)

df.head()

# Total count of HTML elements
html_element_count = df['Body'].str.count('<[^>]+>').sum()
print("HTML Element Count:", html_element_count)

# Total number of special characters
special_char_count = df['Body'].apply(lambda text: sum(1 for char in text if char in string.punctuation)).sum()
print("Special Character Count:", special_char_count)

# Total number of newlines and white spaces
whitespace_count = df['Body'].str.count('\s').sum()
print("Whitespace Count:", whitespace_count)

# Total number of capital letters
uppercase_count = df['Body'].str.count(r'[A-Z]').sum()
print("Uppercase Count:", uppercase_count)

# Total number of stop-words
stopwords_list = stopwords.words('turkish')  # Turkish stop-words list
stopwords_count = df['Body'].apply(lambda text: len([word for word in text.split() if word.lower() in stopwords_list])).sum()
print("Stopwords Count:", stopwords_count)

df.shape

# Check for null values on DataFrame
null_values = df.isnull()

# Calculate the number of null values in each column
null_counts = null_values.sum()

# Get the total number of nulls
total_null_count = null_counts.sum()

print("Total Null Count:", total_null_count)

df.to_csv('clean_news.csv', index=False, encoding='utf-8-sig')